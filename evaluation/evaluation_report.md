# Model Evaluation Report

## Test Set Metrics

- **Accuracy:** 1.0000
- **Precision:** 1.0000
- **Recall:** 1.0000
- **F1 Score:** 1.0000

```
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         3
           1       1.00      1.00      1.00         1

    accuracy                           1.00         4
   macro avg       1.00      1.00      1.00         4
weighted avg       1.00      1.00      1.00         4

```

## Optimal Threshold

- Best F1 at threshold **0.05**

## Cross-Validation (5-fold)

- **Accuracy:** 1.0000 ± 0.0000
- **Precision:** 1.0000 ± 0.0000
- **Recall:** 1.0000 ± 0.0000
- **F1:** 1.0000 ± 0.0000
- **Roc_auc:** 1.0000 ± 0.0000
